#  java

- ▲ 20 Java 中垃圾回收机制中如何判断对象需要回收？常见的 GC 回收算法有哪些？
- ▲ 15 HashMap 与 ConcurrentHashMap 的实现原理是怎样的？ConcurrentHashMap 是如何保证线程安全的？
- ▲ 6 Java 线程间有多少通信方式？
- ▲ 6 Java 类的加载流程是怎样的？什么是双亲委派机制？
- ▲ 5 简述常见的工厂模式以及单例模式的使用场景
- ▲ 5 JVM 中内存模型是怎样的，简述新生代与老年代的区别？
- ▲ 3 Java 常见锁有哪些？ReetrantLock 是怎么实现的？
- ▲ 3 ThreadLocal 实现原理是什么？
- ▲ 3 简述 Spring 的初始化流程
- ▲ 3 简述生产者消费者模型
- ▲ 1 Java 如何高效进行数组拷贝
- ▲ 1 CAS 实现原理是什么？



## final关键字

1. final类不能被继承，没有子类，final类中的方法默认是final的，但是final类中的成员变量默认不是final的。
2. final方法不能被子类覆盖，但可以被继承。
3. final成员变量表示常量，只能被赋值一次，赋值后值不再改变。
4. final不能用于修饰构造方法。

## Java 中接口和抽象类的区别

- 1、一个类可以实现多个接口，但是却只能继承最多一个抽象类；
- 2、抽象类可以包含具体的方法，接口的所有方法都是抽象的；
- 3、抽象类可以声明和使用字段；接口则不能，但接口可以创静态的final常量；
- 4、抽象类中抽象方法的访问类型可以是public，protected，但接口中抽象方法的访问类型只能是public，并且默认为public abstract（省略则自动默认补全）。
- 5、抽象类可以定义构造函数，但是接口不行。
- 6、抽象类中可以有静态方法，接口中不能有静态方法。

##  成员变量和方法的区别？

**成员变量**：包括实例变量和类变量，用static修饰的是类变量，不用static修饰的是实例变量，所有类的成员变量可以通过this来引用。

**类方法：**和类变量一样，可以不用实例，直接用类就可以调用类方法。类方法这不是一个名词，只是单纯的类中描述的一个方法。加了static的方法，在程序中只运行一次，比如你两次实例化对象了，但你实际上只调用了一次static标识的方法。



## Java 如何高效进行数组拷贝

方法1: 自己new数组, 然后for循环复制

方法2: 使用 Arrays.copyOf, 或 System.arraycopy. 本质前者是基于后者的, 两者性能相当, 前者多了2次native调用获取数组元素类型和创建数组.

使用Arrays.copyOf或System.arraycopy的ops是for循环版本的2倍! 经进一步测试, 这个结论在数组较大和较小时都是适用的.

哪怕不进行测试也是很明显的, 既然库函数已经提供这个功能了, 还是native的实现, 那么没道理它的效率比自己for循环实现的版本更低.



## hashMap 1.7 / 1.8 的实现区别

1. 最重要的一点是底层结构不一样，1.7是数组+链表，1.8则是数组+链表+红黑树结构;

2. jdk1.7中当哈希表为空时，会先调用inflateTable()初始化一个数组；而1.8则是直接调用resize()扩容;

3. 插入键值对的put方法的区别，1.8中会将节点插入到链表尾部，而1.7中是采用头插；

4. jdk1.7中的hash函数对哈希值的计算直接使用key的hashCode值，而1.8中则是采用key的hashCode异或上key的hashCode进行无符号右移16位的结果，避免了只靠低位数据来计算哈希时导致的冲突，计算结果由高低位结合决定，使元素分布更均匀；

5. 扩容时1.8会保持原链表的顺序，而1.7会颠倒链表的顺序；而且1.8是在元素插入后检测是否需要扩容，1.7则是在元素插入前；

6. jdk1.8是扩容时通过hash&数组长度==0将链表分散，无需改变hash值，而1.7是通过更新hashSeed来修改hash值达到分散的目的；

7. 扩容策略：1.7中是只要不小于阈值就直接扩容2倍；而1.8的扩容策略会更优化，当数组容量未达到64时，以2倍进行扩容，超过64之后若桶中元素个数不小于7就将链表转换为红黑树，但如果红黑树中的元素个数小于6就会还原为链表，当红黑树中元素不小于32的时候才会再次扩容。

8. **为什么在JDK1.8中进行对HashMap优化的时候，把链表转化为红黑树的阈值是8,而不是7或者不是20呢**

   1）如果选择6和8（**如果链表小于等于6树还原转为链表，大于等于8转为树**），中间有个差值7可以有效防止链表和树频繁转换。假设一下，如果设计成链表个数超过8则链表转换成树结构，链表个数小于8则树结构转换成链表，如果一个HashMap不停的插入、删除元素，链表个数在8左右徘徊，就会频繁的发生树转链表、链表转树，效率会很低。
   2）还有一点重要的就是由于treenodes的大小大约是常规节点的两倍，因此我们仅在容器包含足够的节点以保证使用时才使用它们，当它们变得太小（由于移除或调整大小）时，它们会被转换回普通的node节点，容器中节点分布在hash桶中的频率遵循泊松分布，桶的长度超过8的概率非常非常小。所以作者应该是根据概率统计而选择了8作为阀值

   3）选择8的原因：HashMap在JDK1.8及以后的版本中引入了红黑树结构，若桶中链表元素个数大于等于8时，链表转换成树结构；若桶中链表元素个数小于等于6时，树结构还原成链表。因为红黑树的平均查找长度是log(n)，长度为8的时候，平均查找长度为3，如果继续使用链表，平均查找长度为8/2=4，这才有转换为树的必要。链表长度如果是小于等于6，6/2=3，虽然速度也很快的，但是转化为树结构和生成树的时间并不会太短。

9. 首先HashMap是**线程不安全**的，其主要体现：

   \#1.在jdk1.7中，在多线程环境下，扩容时会造成环形链或数据丢失。死循环 ，扩容时，问题出现在transfer 方法

   \#2.在jdk1.8中，在多线程环境下，会发生数据覆盖的情况。HashMap中put操作的主函数， 注意第6行代码，如果没有hash碰撞则会直接插入元素。如果线程A和线程B同时进行put操作，刚好这两条不同的数据hash值一样，并且该位置数据为null，所以这线程A、B都会进入第6行代码中。假设一种情况，线程A进入后还未进行数据插入时挂起，而线程B正常执行，从而正常插入数据，然后线程A获取CPU时间片，此时线程A不用再进行hash判断了，问题出现：线程A会把线程B插入的数据给**覆盖**，发生线程不安全。

   <img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210121172817067.png" alt="image-20210121172817067" style="zoom:80%;" />

##  HashMap 实现原理，为什么使用红黑树？

https://blog.csdn.net/qq_26542493/article/details/105482732  ==》hashmap实现原理

**使用红黑树原因** ：链表的查询复杂度为o(n)；而红黑树的复杂度能达到o(logn);

**使用红黑树而不用平衡二叉树原因**：java8不是用红黑树来管理

、，而是在hash值相同的情况下（且重复数量大于8），用红黑树来管理数据。 红黑树相当于排序数据，可以自动的使用二分法进行定位，性能较高。一般情况下，hash值做的比较好的话基本上用不到红黑树。红黑树牺牲了一些查找性能 但其本身并不是完全平衡的二叉树。因此插入删除操作效率略高于AVL树。
AVL树用于自平衡的计算牺牲了插入删除性能，但是因为最多只有一层的高度差，查询效率会高一些。



## ConcurrentHashMap 的实现原理是怎样的？

链接==》https://blog.csdn.net/qq_26542493/article/details/105651338

**JDK1.7**

本质上还是采用链表+数组的形式存储键值对的。但是，为了提高并发，把原来的整个 table 划分为 n 个 Segment 。所以，从整体来看，它是一个由 Segment 组成的数组。然后，每个 Segment 里边是由 HashEntry 组成的数组，每个 HashEntry之间又可以形成链表。我们可以把每个 Segment 看成是一个小的 HashMap，其内部结构和 HashMap 是一模一样的。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210122232811511.png" alt="image-20210122232811511" style="zoom: 50%;" />



当对某个 Segment 加锁时，如图中 Segment2，并不会影响到其他 Segment 的读写。每个 Segment 内部自己操作自己的数据。这样一来，我们要做的就是尽可能的让元素均匀的分布在不同的 Segment中。最理想的状态是，所有执行的线程操作的元素都是不同的 Segment，这样就可以降低锁的竞争。

**JDK1.8**

需要说明的是，JDK 1.8 的 CHM（ConcurrentHashMap） 实现，完全重构了 1.7 。不再有 Segment 的概念，只是为了兼容 1.7 才申明了一下，并没有用到。因此，不再使用分段锁，而是给数组中的每一个头节点（为了方便，以后都叫桶）都加锁，锁的粒度降低了。并且，用的是 Synchronized 锁。CAS操作

可能有的小伙伴就有疑惑了，不是都说同步锁是重量级锁吗，这样不是会影响并发效率吗？

确实之前同步锁是一个重量级锁，但是在 JDK1.6 之后进行了各种优化之后，它已经不再那么重了。引入了偏向锁，轻量级锁，以及锁升级的概念，而且，据说在更细粒度的代码层面上，同步锁已经可以媲美 Lock 锁，甚至是赶超了。 除此之外，它还有很多优点，这里不再展开了。感兴趣的可以自行查阅同步锁的锁升级过程，以及它和 Lock 锁的区别。

在 1.8 CHM 中，底层存储结构和 1.8 的 HashMap 是一样的，都是数组+链表+红黑树。不同的就是，多了一些并发的处理。

文章开头我们提到了，在 1.8 HashMap 中的线程安全问题，就是因为在多个线程同时操作同一个桶的头结点时，会发生值的覆盖情况。那么，顺着这个思路，我们看一下在 CHM 中它是怎么避免这种情况发生的吧。

## ConcurrentHashMap 是如何保证线程安全的？

1.7：使用分段锁（Segment ）

1.8：完全重构了1.7的方案，使用了synchronized关键字



从JDK1.7版本的ReentrantLock+Segment+HashEntry，到JDK1.8版本中synchronized+CAS+HashEntry+红黑树,**总结如下**：
1、JDK1.7版本锁的粒度是基于Segment的，包含多个HashEntry，而JDK1.8实现降低锁的粒度就是HashEntry（首节点）
2、JDK1.8版本的数据结构变得更加简单，去掉了Segment这种数据结构，使用synchronized来进行同步锁粒度降低，所以不需要分段锁的概念，实现的复杂度也增加了
3、JDK1.8使用红黑树来优化链表，基于长度很长的链表的遍历是一个很漫长的过程，而红黑树的遍历效率是很快的，代替一定阈值的链表，这样形成一个最佳拍档



## hashmap 和 hashtable 的区别是什么？

- HashMap和HashTable的类继承体系：两个类的继承体系有些不同。虽然都实现了Map、Cloneable、Serializable三个接口。但是HashMap继承自抽象类AbstractMap，而HashTable继承自抽象类Dictionary。其中Dictionary类是一个已经被废弃的类，这一点我们可以从它代码的注释中看到。同时我们看到HashTable比HashMap多了两个公开方法。一个是elements，这来自于抽象类Dictionary，鉴于该类已经废弃，所以这个方法也就没什么用处了。另一个多出来的方法是contains，这个多出来的方法也没什么用，因为它跟containsValue方法功能是一样的

- Null Key & Null Value：HashMap是支持null键和null值的，而HashTable在遇到null时，会抛出NullPointerException异常。这并不是因为HashTable有什么特殊的实现层面的原因导致不能支持null键和null值，这仅仅是因为HashMap在实现时对null做了特殊处理，将null的hashCode值定为了0，从而将其存放在哈希表的第0个bucket中

  数据结构：HashMap和HashTable都使用哈希表来存储键值对。在数据结构上是基本相同的，都创建了一个继承自Map.Entry的私有的内部类Entry，每一个Entry对象表示存储在哈希表中的一个键值对。

- 算法：上一小节已经说了用来表示哈希表的内部数据结构。HashMap/HashTable还需要有算法来将给定的键key，映射到确定的hash桶（数组位置）。需要有算法在哈希桶内的键值对多到一定程度时，扩充哈希表的大小（数组的大小）。HashTable默认的初始大小为11，之后每次扩充为原来的2n+1。HashMap默认的初始化大小为16，之后每次扩充为原来的2倍。还有我没列出代码的一点，就是如果在创建时给定了初始化大小，那么HashTable会直接使用你给定的大小，而HashMap会将其扩充为2的幂次方大小。方便位运算，因此效率偏高

- 计算hash值的方法不一样：hashmap==》计算hash值，先调用hashCode方法计算出来一个hash值，再将hash与右移16位后相**异或**，从而得到新的hash值。hashtable==》计算key的hashCode()来得到hash值就为最终hash值。计算索引位置方法不同：
  HashMap在求hash值对应的位置索引时，`index = (n - 1) & hash`。将哈希表的大小固定为了2的幂，因为是取模得到索引值，**故这样取模时，不需要做除法，只需要做位运算。位运算比除法的效率要高很多。**HashTable在求hash值位置索引时计算index的方法：&0x7FFFFFFF的目的是为了将负的hash值转化为正值，因为hash值有可能为负数，而&0x7FFFFFFF后，只有符号位改变，而后面的位都不变。

- **线程安全**：hashmap是不安全的  hashtable是安全的，hashtable使用的是一个大锁synchronized来锁住整个数组节点

  

## 简述 Java的反射机制

**反射机制**：1、在运行状态中，对于任意一个类，都能够知道这个类的属性和方法。

​                   2、对于任意一个对象，都能够调用它的任何方法和属性。这种动态获取信息以及动态调用对象的方法的功能称为JAVA的反射

（1、得到一个对象所属的类；2、获取一个类的所有成员变量和方法；3、在运行时创建对象；4、在运行时调用对象的方法。）

**反射的作用**

1、在运行时判断任意一个对象所属的类； 

2、在运行时构造任意一个类的对象； 

3、在运行时判断任意一个类所具有的成员变量和方法； 

4、在运行时调用任意一个对象的方法；

5、生成动态代理。

**反射原理**

反射的实现主要借助以下四个类：Class、Constructor、Field、Method ；
1、通过Class类获取类对象的三种方法：
第一种：通过类名获得:Class<?> class = *ClassName*.class;
第二种：通过类名全路径获得：Class<?> class = Class.forName(“类名全路径”);
第三种：通过实例对象获得：Class<?> class = object.getClass();

2、通过Class类获取实现类实例化：
Object o = (Object) c.newInstance() ; (其中c为Class类的实例化对象）

3、获取类中的构造方法：![你好](https://images2015.cnblogs.com/blog/831179/201703/831179-20170311161343451-803699800.png)![在这里插入图片描述](https://images2015.cnblogs.com/blog/831179/201703/831179-20170311161408982-698240323.png)
4、获取类中的属性：

![在这里插入图片描述](https://images2015.cnblogs.com/blog/831179/201703/831179-20170311161735389-1882210002.png)
![在这里插入图片描述](https://images2015.cnblogs.com/blog/831179/201703/831179-20170311161755498-1621406504.png)

5、获取类中的方法：

![在这里插入图片描述](https://images2015.cnblogs.com/blog/831179/201703/831179-20170311161823873-503164825.png)
![在这里插入图片描述](https://images2015.cnblogs.com/blog/831179/201703/831179-20170311161907357-844512641.png)

**注：**

**1、ClassForName 与 ClassLoader 的区别：**
1）class.forName()除了将类的.class文件加载到jvm中之外，还会对类进行解释，执行类中的static块，还会执行给静态变量赋值的静态方法；
2）classLoader只干一件事情，就是将.class文件加载到jvm中，不会执行static中的内容,只有在newInstance才会去执行static块。





##  CAS 实现原理是什么

  在计算机科学中，比较和交换（Conmpare And Swap）是用于实现多线程同步的原子指令。 它将内存位置的内容与给定值进行比较，只有在相同的情况下，将该内存位置的内容修改为新的给定值。 这是作为单个原子操作完成的。 原子性保证新值基于最新信息计算; 如果该值在同一时间被另一个线程更新，则写入将失败。 操作结果必须说明是否进行替换; 这可以通过一个简单的布尔响应（这个变体通常称为比较和设置），或通过返回从内存位置读取的值来完成

CAS可以有效的提升并发的效率，但同时也会引入ABA问题。

 如线程1从内存X中取出A，这时候另一个线程2也从内存X中取出A，并且线程2进行了一些操作将内存X中的值变成了B，然后线程2又将内存X中的数据变成A，这时候线程1进行CAS操作发现内存X中仍然是A，然后线程1操作成功。虽然线程1的CAS操作成功，但是整个过程就是有问题的。比如链表的头在变化了两次后恢复了原值，但是不代表链表就没有变化。

 所以JAVA中提供了AtomicStampedReference/AtomicMarkableReference来处理会发生ABA问题的场景，主要是在对象中额外再增加一个标记来标识对象是否有过变更。



CAS操作包括三个操作数–内存位置V，预期原值A，新值B。
分为三个步骤：

1. 读取内存中的值
2. 将读取的值和预期的值进行比较
3. 如果比较的结3果符合预期，则写入新值；如果不符合，则什么都不做

原子操作就是靠CAS算法保证的，那***一个CPU下会不会同时两个线程同时比较且同时替换***呢？不会。
因为CAS是一种系统原语：
**原语由若干条指令组成的，用于完成一定功能的一个过程。
原语的执行必须是连续的，在执行过程中不允许被中断。**



## Synchronized 锁和Lock锁的区别

1.首先synchronized是java内置关键字，在jvm层面，Lock是个java类；

2.synchronized无法判断是否获取锁的状态，Lock可以判断是否获取到锁；

3.synchronized会自动释放锁(a 线程执行完同步代码会释放锁 ；b 线程执行过程中发生异常会释放锁)，Lock需在finally中手工释放锁（unlock()方法释放锁），否则容易造成线程死锁；

4.用synchronized关键字的两个线程1和线程2，如果当前线程1获得锁，线程2线程等待。如果线程1阻塞，线程2则会一直等待下去，而Lock锁就不一定会等待下去，如果尝试获取不到锁，线程可以不用一直等待就结束了；

5.synchronized的锁可重入、不可中断、非公平，而Lock锁可重入、可中断、可公平（两者皆可）

6.Lock锁适合大量同步的代码的同步问题，synchronized锁适合代码少量的同步问题。

7.synchronized等待不可中断，除非抛出异常或者执行完成， Lock可以中断，通过interrupt()可中断



## java中各种锁

![image-20210123211901853](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20210123211901853.png)

## 线程池

**1、产生原因：**很多线程执行，把且执行时间较短，频繁创建和销毁会浪费时间，那么有没有一种办法使得线程可以复用，就是执行完一个任务，并不被销毁，而是可以继续执行其他的任务？在Java中可以通过线程池来达到这样的效果。

**2、线程池的优势**

（1）、降低系统资源消耗，通过重用已存在的线程，降低线程创建和销毁造成的消耗；
 （2）、提高系统响应速度，当有任务到达时，通过复用已存在的线程，无需等待新线程的创建便能立即执行；
 （3）方便线程并发数的管控。因为线程若是无限制的创建，可能会导致内存占用过多而产生OOM，并且会造成cpu过度切换（cpu切换线程是有时间成本的（需要保持当前执行线程的现场，并恢复要执行线程的现场））。
 （4）提供更强大的功能，延时定时线程池。

**3、线程池流程**

![img](https://upload-images.jianshu.io/upload_images/6024478-88ee7b20f8f45825.png?imageMogr2/auto-orient/strip|imageView2/2/format/webp)

1、判断核心线程池是否已满，没满则创建一个新的工作线程来执行任务。已满则。
 2、判断任务队列是否已满，没满则将新提交的任务添加在工作队列，已满则。
 3、判断整个线程池是否已满，没满则创建一个新的工作线程来执行任务，已满则执行饱和策略。

（1、判断线程池中当前线程数是否大于核心线程数，如果小于，在创建一个新的线程来执行任务，如果大于则
 2、判断任务队列是否已满，没满则将新提交的任务添加在工作队列，已满则。
 3、判断线程池中当前线程数是否大于最大线程数，如果小于，则创建一个新的线程来执行任务，如果大于，则执行饱和策略。）

**4、java中的核心类**：ThreadPoolExecutor

**5、线程池的状态**

在ThreadPoolExecutor中定义了一个volatile变量，另外定义了几个static final变量表示线程池的各个状态：

```
volatile int runState;
static final int RUNNING    = 0;
static final int SHUTDOWN   = 1;
static final int STOP       = 2;
static final int TERMINATED = 3;
```

 　runState表示当前线程池的状态，它是一个volatile变量用来保证线程之间的可见性；

　　下面的几个static final变量表示runState可能的几个取值。

　　当创建线程池后，初始时，线程池处于RUNNING状态；

　　如果调用了shutdown()方法，则线程池处于SHUTDOWN状态，此时线程池不能够接受新的任务，它会等待所有任务执行完毕；

　　如果调用了shutdownNow()方法，则线程池处于STOP状态，此时线程池不能接受新的任务，并且会去尝试终止正在执行的任务；

　　当线程池处于SHUTDOWN或STOP状态，并且所有工作线程已经销毁，任务缓存队列已经清空或执行结束后，线程池被设置为TERMINATED状态。

**6、总结**

- 如果当前线程池中的线程数目小于corePoolSize，则每来一个任务，就会创建一个线程去执行这个任务；
- 如果当前线程池中的线程数目>=corePoolSize，则每来一个任务，会尝试将其添加到任务缓存队列当中，若添加成功，则该任务会等待空闲线程将其取出去执行；若添加失败（一般来说是任务缓存队列已满），则会尝试创建新的线程去执行这个任务；
- 如果当前线程池中的线程数目达到maximumPoolSize，则会采取任务拒绝策略进行处理；
- 如果线程池中的线程数量大于 corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止，直至线程池中的线程数目不大于corePoolSize；如果允许为核心池中的线程设置存活时间，那么核心池中的线程空闲时间超过keepAliveTime，线程也会被终止。

**7.任务缓存队列及排队策略**

　　在前面我们多次提到了任务缓存队列，即workQueue，它用来存放等待执行的任务。

　　workQueue的类型为BlockingQueue<Runnable>，通常可以取下面三种类型：

　　1）ArrayBlockingQueue：基于数组的先进先出队列，此队列创建时必须指定大小；

　　2）LinkedBlockingQueue：基于链表的先进先出队列，如果创建时没有指定此队列大小，则默认为Integer.MAX_VALUE；

　　3）synchronousQueue：这个队列比较特殊，它不会保存提交的任务，而是将直接新建一个线程来执行新来的任务。

**8.任务拒绝策略**

　　当线程池的任务缓存队列已满并且线程池中的线程数目达到maximumPoolSize，如果还有任务到来就会采取任务拒绝策略，通常有以下四种策略：

```
ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。
ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。
ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）
ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务
```

**9.线程池的关闭**

　　ThreadPoolExecutor提供了两个方法，用于线程池的关闭，分别是shutdown()和shutdownNow()，其中：

- shutdown()：不会立即终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务

- shutdownNow()：立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务

  

##  Java 中垃圾回收机制中如何判断对象需要回收



- ## 引用计数算法

  **算法思路：**

  1）给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值加1；

  2）当引用失效时，计数器值就减1；

  3）任何时刻计数器为0的对象就是不可能再被使用的；

  **优点：**

  实现简单，判定效率高；

  **缺点：**

   很难解决对象之间相互循环引用的问题。**所以主流的虚拟机里没有选用引用计数算法来管理内存的。**

  因为相互引用着对方，导致它们的引用计数都不为0，于是引用计数算法无法通知GC收集器回收它们。

- ## 可达性分析算法

  **算法思路：**

    通过一系列的称为"GC Roots"的对象作为起始点，从这些节点开始往下搜索，搜索所有走过的路径

  称为引用链(Reference Chain)，当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。

在Java语言中，可以作为GC Roots的对象包括下面几种：

1）虚拟机栈（栈帧中的本地变量表）中引用的对象。

2）方法区中静态属性引用的对象。

3）方法区中常量引用的对象，在jdk7后被移到堆中。

4）本地方法栈中JNI(即一般说的Native方法)引用的对象。

​       **优点**

​          更加精确和严谨，可以分析出循环数据结构相互引用的情况；

​      **缺点**

​          1）实现比较复杂；

​          2）需要分析大量数据，消耗大量时间；

​          3）分析过程需要GC停顿（引用关系不能发生变化），即停顿所有Java执行线程（称为"Stop The World"，

​                是垃圾回收重点关注的问题）；

## 常见的 GC 回收算法

- ### 标记-清除算法

  **1、算法思路**

    "标记-清除"（Mark-Sweep）算法是最基础的收集算法，之所以叫做最基础的收集算法，是因为很多收集算法都是

  基于这种该算法思想对其不足进行改进得到的。顾名思义，"标记-清除"算法分为"标记"和"清除"两个阶段实现。

  **1）标记**

    **首先标记出所有需要回收的对象，要宣告一个对象死亡，至少要经历两次标记过程。**

    **第一次标记**

    如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，那它将会被第一次标记

  并且进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。当对象没有覆盖finalize()方法，

  或者finalize()方法已经被虚拟机调用过，虚拟机将这两种情况都视为"没有必要执行"。

    如果这个对象被判定为有必要执行finalize()方法，那么这个对象将会被放置在一个叫做F-Queue的

  队列中，并在稍后由一个虚拟机自动建立的、低优先级的Finalizer线程去触发这个方法。

    **第二次标记**

    GC将对F-Queue队列中的对象进行第二次小规模标记；finalize()方法是对象逃脱死亡的最后一次机会：

  如果对象在其finalize()方法中重新与引用链上任何一个对象建立关联，第二次标记时会将其移出"即将回收"的集合；

  如果对象没有，也可以认为对象已死，可以回收了；

  **2）清除**

    两次标记后，还在"即将回收"集合的对象将被统一回收；

​       **2、优点：**实现简单

​       **3、缺点：**效率问题（标记和清除两个过程的效率都不高），空间问题（标记清除之后会产生大量的不连续的内存碎片，空间碎片太多可能导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另外一次垃圾收集动作。）

​        **4、应用场景：**针对CMS收集器使用



- ### 复制算法

  **1、为了解决"标记-清除"算法的效率问题**

  **2、算法思路：**

    1）将可用内存按照容量划分为大小相等的两块，每次只使用其中一块。

    2）当一块内存用完后，就将还存活着的对象复制到另外一块上面，然后再把已使用多的内存空间一次清    掉。这样使得每次都对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。

  **3、优点：**不会残生内存碎片，内存分配实现简单，高效

  **4、缺点：**

  1）空间浪费

     可用内存缩减为原来的一半，太过浪费（解决：可以改良，不按1:1比例划分）；

    2）效率随对象存活率升高而变低

    当对象存活率较高时，需要进行较多复制操作，效率将会变低；

  **5、应用场景：**

  现在商业虚拟机都采用这种收集算法来回收新生代，用该算法的垃圾收集器比较多，

  **如Serial收集器、ParNew收集器、Parallel Scavenge收集器、G1（从局部看）**。

  

- ### 标记-整理算法

  **1、算法思路：**

  "标记-整理"（Mark-Compact）算法的标记过程仍然与"标记-清除"算法一样，但后续步骤不是直接对回收对象进行清理，而是让所有存活的对象都向一端移动，然后清理掉端边界以外的内存

  **2、优点：**

  1）不会像复制算法，效率随对象存活率升高而变低。

  老年代特点：对象存活率高，没有额外的空间可以分配担保；所以老年代一般不能直接选用复制算法；而选用标记-整理算法；

  2）不会像标记-清除算法，产生内存碎片因为清除前，进行了整理，存活对象都集中到空间一侧；

  **3、缺点：**主要是效率问题：除像标记-清除算法的标记过程外，还多了需要整理的过程，效率更低

  **4、应用场景：**

  很多垃圾收集器采用这种算法来回收老年代；如Serial Old收集器、G1（从整体看）；

  

- ### 分代收集算法

  **"分代收集"（Generational Collection）算法结合不同的收集算法处理不同区域。**

  **1、算法思路：**

   当前虚拟机的垃圾收集都采用"分代收集"算法，这种算法并没有什么新的思想，只是根据对象的

  存活申请周期的不同将内存划分为几块，这样就可以根据各个年代的特点采用最适当的收集算法。

  java堆分为新生代和老年代。

    **1）新生代**

     在新生代中，每次垃圾收集都发现有大批量对象死去，只有少量存活，就选用复制算法，

  只需要付出少量的存活对象的复制成本就可以完成收集。

    **2）老年代**

    在老年代中对象存活率高、没有额外空间对它进行分配担保，就必须使用"标记-清除"或"标记-整理"算法

  来进行回收。

  **2、优点：**可以根据各个年代的特点采用最适当的收集算法

  **3、缺点：**仍然不能控制每次垃圾收集的时间

  **4、应用场景：**

   目前几乎所有商业虚拟机的垃圾收集器都采用分代收集算法；如HotSpot虚拟机中全部垃圾收集器：

  Serial、ParNew、Parallel Scavenge、Serial Old、Parallel Old、CMS、G1（也保留）；

